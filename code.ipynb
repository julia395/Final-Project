{
 "cells": [
  {
   "cell_type": "code",
   "source": "import pandas as pd\nimport numpy as np\nimport streamlit as st\nimport requests \nimport matplotlib.pyplot as plt\n\nimport nltk\nnltk.download('punkt')\nfrom nltk.tokenize import word_tokenize\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\nfrom nltk import FreqDist",
   "metadata": {
    "cell_id": "9d57945d7b7344a4bb013318f39812c4",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "1980151c",
    "execution_start": 1652073419088,
    "execution_millis": 4123,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 390.9375
   },
   "outputs": [
    {
     "name": "stderr",
     "text": "2022-05-09 05:17:00.195 INFO    matplotlib.font_manager: generated new fontManager\n[nltk_data] Downloading package punkt to /root/nltk_data...\n[nltk_data]   Unzipping tokenizers/punkt.zip.\n[nltk_data] Downloading package stopwords to /root/nltk_data...\n[nltk_data]   Unzipping corpora/stopwords.zip.\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": "#add title to page\nst.title('Yelp Business Data')\n\n#reading updated business and review csv\nbusiness = pd.read_csv('bussiness_updated.csv')\nreviews = pd.read_csv('df_review_bus.csv')\n\n#dropping some columns\nbusiness = business.drop(columns=['occurance_of_category','is_open'])\n\n#displaying datframe of business data\nst.dataframe(data=business, width=None, height=None)\n\n#have user select category\nwith st.sidebar:\n    st.subheader(\"User Inputs for Graph\")\n    category_chosen = st.sidebar.selectbox(\"Select a Category\", reviews.categories.unique())\n\n#subset of yelp data based on the category chosen \ncategory_subset = reviews[reviews['categories'] == category_chosen]\n\n#taking all reviews from dataframe, joining them into one string, and making all the\n#characters lowercase \nreviews_txt = ' '.join(category_subset['text']).lower()\n\n#splitting into tokens\nword_tokens = word_tokenize(reviews_txt)\n\n#making list of stop words\nstop_words = set(stopwords.words('english'))\n\n#filterng out stop words and none words\nwords = []\nfor word in word_tokens:\n    if word.isalpha() and word not in stop_words:\n        words.append(word)\n\n#getting frequency distrabution\nfrequency = FreqDist(words)\n\n#creating dataframes\ndist = pd.DataFrame(frequency.items(),columns=['word', 'freq'])\n\n#sorting by frequency \ndist = dist.sort_values(by='freq', ascending=False).reset_index(drop=True)\n\n#selecting only top 10\ndist = dist.iloc[:10, :]\n\n#getting data for graph \nwords = dist['word']\nfrequency = dist['freq']\n\n#create figure\nfig = plt.figure()\n#title for graph \ntitle = f\"10 Most Frequent Words in Yelp Reviews for {category_chosen} Businesses\"\n#setting up graph and labels\nplt.barh(words, frequency)\nplt.ylabel('Word')\nplt.xlabel('Word Frequency')\nplt.title(title)\nst.pyplot(fig)\n\nst.write(\"Only includes reviews for top 1% of businesses with the most reviews within each category\")\n\n",
   "metadata": {
    "cell_id": "8028aad6fd9f45ee9a9fd75dbf8949e9",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "dbab2b38",
    "execution_start": 1652073592432,
    "execution_millis": 604,
    "deepnote_table_state": {
     "pageSize": 10,
     "pageIndex": 0,
     "filters": [],
     "sortBy": []
    },
    "deepnote_table_loading": false,
    "owner_user_id": "f87243a2-d6b3-413a-8ff4-deba461fd370",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 1788,
    "deepnote_output_heights": [
     null,
     21.1875
    ]
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 4,
     "data": {
      "application/vnd.deepnote.dataframe.v3+json": {
       "column_count": 2,
       "row_count": 10,
       "columns": [
        {
         "name": "word",
         "dtype": "object",
         "stats": {
          "unique_count": 10,
          "nan_count": 0,
          "categories": [
           {
            "name": "great",
            "count": 1
           },
           {
            "name": "place",
            "count": 1
           },
           {
            "name": "8 others",
            "count": 8
           }
          ]
         }
        },
        {
         "name": "freq",
         "dtype": "int64",
         "stats": {
          "unique_count": 10,
          "nan_count": 0,
          "min": "36",
          "max": "73",
          "histogram": [
           {
            "bin_start": 36,
            "bin_end": 39.7,
            "count": 1
           },
           {
            "bin_start": 39.7,
            "bin_end": 43.4,
            "count": 1
           },
           {
            "bin_start": 43.4,
            "bin_end": 47.1,
            "count": 2
           },
           {
            "bin_start": 47.1,
            "bin_end": 50.8,
            "count": 1
           },
           {
            "bin_start": 50.8,
            "bin_end": 54.5,
            "count": 1
           },
           {
            "bin_start": 54.5,
            "bin_end": 58.2,
            "count": 1
           },
           {
            "bin_start": 58.2,
            "bin_end": 61.900000000000006,
            "count": 0
           },
           {
            "bin_start": 61.900000000000006,
            "bin_end": 65.6,
            "count": 2
           },
           {
            "bin_start": 65.6,
            "bin_end": 69.30000000000001,
            "count": 0
           },
           {
            "bin_start": 69.30000000000001,
            "bin_end": 73,
            "count": 1
           }
          ]
         }
        },
        {
         "name": "_deepnote_index_column",
         "dtype": "int64"
        }
       ],
       "rows": [
        {
         "word": "great",
         "freq": 73,
         "_deepnote_index_column": 0
        },
        {
         "word": "place",
         "freq": 63,
         "_deepnote_index_column": 1
        },
        {
         "word": "time",
         "freq": 62,
         "_deepnote_index_column": 2
        },
        {
         "word": "one",
         "freq": 57,
         "_deepnote_index_column": 3
        },
        {
         "word": "store",
         "freq": 53,
         "_deepnote_index_column": 4
        },
        {
         "word": "love",
         "freq": 48,
         "_deepnote_index_column": 5
        },
        {
         "word": "get",
         "freq": 47,
         "_deepnote_index_column": 6
        },
        {
         "word": "experience",
         "freq": 45,
         "_deepnote_index_column": 7
        },
        {
         "word": "service",
         "freq": 42,
         "_deepnote_index_column": 8
        },
        {
         "word": "always",
         "freq": 36,
         "_deepnote_index_column": 9
        }
       ]
      },
      "text/plain": "         word  freq\n0       great    73\n1       place    63\n2        time    62\n3         one    57\n4       store    53\n5        love    48\n6         get    47\n7  experience    45\n8     service    42\n9      always    36",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>word</th>\n      <th>freq</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>great</td>\n      <td>73</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>place</td>\n      <td>63</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>time</td>\n      <td>62</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>one</td>\n      <td>57</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>store</td>\n      <td>53</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>love</td>\n      <td>48</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>get</td>\n      <td>47</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>experience</td>\n      <td>45</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>service</td>\n      <td>42</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>always</td>\n      <td>36</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "65197958-c90e-4d38-9148-1d301a4d0667",
    "deepnote_to_be_reexecuted": true,
    "source_hash": "85393b06",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 3447
   },
   "source": "#reading business csv\nbusiness = pd.read_csv('business.csv')\n\n#splitting the string of categories for each row into a list \ncategories = business['categories'].str.split(\", \")\n\n#replacing the categories column with a list for each row \nbusiness['categories'] = categories\n\n#creating a list of all the categories by iterating through the nested list \n#of categories and flattening the list \nflatlist = []\nfor sublist in categories:\n    for element in sublist:\n        flatlist.append(element)\n\n#removing duplicates from the flattened list of categories \n#category_list = []\n#for category in flatlist:\n #   if category not in category_list:\n  #     category_list.append(category)\n\n#changing flattened list of all categories into pandas series and counting occurance \n#of each category then creating a dictionary\ncategories_series = pd.Series(flatlist)\noccurances = categories_series.value_counts()\noccurances_dict = occurances.to_dict()\n\n# keeping only one category for each business based on which category has the \n# most businesses\n\n#add column of number of occurances\nbusiness_exploded = business.explode('categories')\noccur = business_exploded['categories'].map(occurances_dict)\nbusiness_exploded['occurance_of_category'] = occur\n\n#sort rows by business id then occurance of category so the same business is kept \n#together and the most popular category for the business will be listed first\nbusiness = business_exploded.sort_values(by=['business_id','occurance_of_category'], ascending=False)\n\n#keeping only one row for each business that has the most popular category\nbusiness = business.drop_duplicates(subset='business_id', keep='first')\n\n# keeping only businesses that in top 1 percentile of businesses with most of reviews within each category \nrank = business.groupby('categories')['review_count'].rank(pct=True)\nbusiness['percent_rank'] = rank\ntop_reviewed_bus = business[business['percent_rank'] >= 0.99]\n\nbus_id_list = top_reviewed_bus['business_id'].tolist()\n\nreview_df = pd.DataFrame()\n\n#load csv file i just created\ndf_yelp_data = pd.read_csv('df_review_bus.csv')\n\n#change time_created to date\ndf_yelp_data['time_created']= pd.to_datetime(df_yelp_data['time_created'])\n\n#go back and change for streamlit\n\n#category_chosen = st.sidebar.selectbox(\"Select a Category\", df_yelp_data.categories.unique())\n####category_chosen = 'Restaurants'\n\n#subset of yelp data based on the ctegory chosen \n####category_subset = df_yelp_data[df_yelp_data['categories'] == category_chosen]\n\n#filtering catergory subset for only reviews after or on march 1 2022\n####aft_mar_2022 = category_subset[category_subset['time_created'] >= 'March 01, 2022 00:00']\naft_mar_2022 = df_yelp_data[df_yelp_data['time_created'] >= 'March 01, 2022 00:00']\n\n#filtering caeroy subset to get only reviews from during major covid period between \n#march 2020 and march 2022\nbef_mar_2022 = df_yelp_data[df_yelp_data['time_created'] < 'March 01, 2022 00:00']\ncovid = bef_mar_2022[bef_mar_2022['time_created'] > 'March 01, 2020 00:00']\n\n\n#taking all of the reviews and joininging them into one long string and making all \n#of the letters lowercase \ntxt_aft_2022 = ' '.join(aft_mar_2022['text']).lower()\ntxt_covid = ' '.join(covid['text']).lower()\n\nstop_words = set(stopwords.words('english'))\n\n# iterating over list of words used during covid \n#using if statment to filter out anything that isnt a word and stop words\n#is_alpha method returns True if all the characters in the string are letters (a-z).\ncovid_words = []\nfor word in word_tokens_covid:\n    if word.isalpha() and word not in stop_words:\n        covid_words.append(word)\n\n#amount_of_covid_words = len(covid_words)\n\n#doing same thing for words from after covid\nafter_words = []\nfor word in word_tokens_after:\n    if word.isalpha() and word not in stop_words:\n        after_words.append(word)\n\n#amount_of_words_a = len(after_words)\n\n#using The FreqDist function from nltk library to get frequency distribution \n#of all the words in each list \ncovid_frequency = FreqDist(covid_words)\nafter_frequency = FreqDist(after_words)\n\n#creating a dataframe for each time period \ncovid_dist = pd.DataFrame(covid_frequency.items(),columns=['word', 'freq_covid'])\nafter_dist = pd.DataFrame(after_frequency.items(),columns=['word', 'freq_after'])\n#with the word 20 most used words and their frequency \n#covid_dist = pd.DataFrame(covid_frequency.most_common(20),columns=['word', 'freq_covid'])\n#after_dist = pd.DataFrame(after_frequency.most_common(20),columns=['word', 'freq_after'])\n\n#making a list of the frquency of each word used doing covid \ncovid_frequency = covid_dist[\"freq_covid\"].tolist()\n\n#getting sum of all frequencies \ntotal_frequencies = sum(covid_frequency)\n\n#iteratting through the frequency of covid words and dividing it by the sum of \n#all frquencies to calculate percentage and appending it to a list \ncovid_percentage = []\nfor freq in covid_frequency:\n    percent = freq/total_frequencies\n    #formated = \"{:.2%}\".format(percent)\n    covid_percentage.append(percent)\n\n#adding percentage to the dataframe\ncovid_dist['percent_covid_freq'] = covid_percentage\n\ncovid_dist\n\n#doing the same thing for after covid words \n\n#making a list of the frquency of each word used doing covid\na_frequency = after_dist[\"freq_after\"].tolist()\n\n#getting sum of all frequencies \ntotal_frequencies = sum(covid_frequency)\n\n#iteratting through the frequency of words after covid and dividing it by the sum of \n#all frquencies to calculate percentage and appending it to a list \na_percentage = []\nfor freq in a_frequency:\n    percent = freq/total_frequencies\n    a_percentage.append(percent)\n\n#adding percentage to the dataframe\nafter_dist['percent_after_freq'] = a_percentage\n\nafter_dist\n\n#merging the dataframes for both time periods \ndf_freq_words = pd.merge(covid_dist, after_dist, on='word',how='outer')\n\n#sort words were in both tables but some were only in one so there are \n#a lot of nas so filling them in with zeros \ndf_freq_words.fillna(0)\n\n# if positive then mentioned more during covid \ndf_freq_words['percent_diff'] = df_freq_words['percent_covid_freq'] - df_freq_words['percent_after_freq']\n\n\n\n\n##### Title and intro\n\n#st.title( 'Example Streamlit App' )\n#st.write( '''\n#This app is very small and does almost nothing.\n#It's just an example.\n#''' )\n\n\n##### Inputs\n\n#st.header( 'Choose two numbers' )\n#a = st.slider( label='a', min_value=1, max_value=10, value=2, step=1 )\n#b = st.slider( label='b', min_value=1, max_value=10, value=3, step=1 )\n\n\n##### Output\n\n#st.header( 'Tiny computations')\n#st.write( f'{a} + {b} = {a+b}' )\n#st.write( f'{a} - {b} = {a-b}' )\n#st.write( f'{a} * {b} = {a*b}' )\n#st.write( f'{a} / {b} = {a/b}' )",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=3c5109e0-d4f5-47cd-9c2e-1a9d1a674c6f' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "tags": [],
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "orig_nbformat": 2,
  "deepnote": {},
  "deepnote_notebook_id": "36fc1949-f846-414b-a5d2-24b7a2d0a471",
  "deepnote_execution_queue": []
 }
}